\begin{abstract}
Linear Discriminant Analysis and Principal Component Analysis are two dimensionality reduction methods that have proven to be very useful in a number of situations by allowing to gain a better insight of the true latent structure of the data, removing noise and correlation, hence, improving classification results. This paper gives a basic introduction to dimensionality reduction, focusing on the to previously mentioned methods. We then emphasize the limitations encountered while using PCA and LDA, which lead us to the use of the famous kernel-trick and the presentation of Kernel LDA and Kernel PCA.
\end{abstract}