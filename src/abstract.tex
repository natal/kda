\begin{abstract}
Linear Discriminant Analysis and Principal Component Analysis are two dimensionality reduction
methods that have proven to be very useful in a number of situations by enabling a better
insight into the true latent structure of the data, removing noise and correlation, hence, improving
classification results. This paper gives a basic introduction to dimensionality reduction, focusing
on the methods previously mentioned. We then emphasize the limitations encountered while using PCA
and LDA, which paves the way for the famous kernel-trick to be introduced in the classic PCA and
LDA.  \end{abstract}
