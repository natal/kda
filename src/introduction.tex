\paragraph{}
Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) are two methods used to reduce dimension of some data-set. They are very useful as a pre-processing step, which has proved to greatly improve results of further data analysis by removing noise, de-correlating and reducing the dimension of the data. This step helps to get a better insight into the true latent structure of the data-set. This methods are widely used in a variety of applications where data-analysis is involved such as data-mining, classification, text analysis and computer vision.

In sections \ref{sec.pca} and \ref{sec.lda} we present the basic version of PCA and LDA. In section \ref{sec.kerneltrick}, we outline their limitations and introduce the famous \emph{Kernel Trick} to overcome them. Section \ref{sec.kpca} and \ref{sec.klda} describe the equations of PCA and LDA adapted for the kernel trick.